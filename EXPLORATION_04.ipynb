{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adopted-minnesota",
   "metadata": {},
   "source": [
    "# EXPLORATION 04\n",
    "# 멋진 작사가 만들기\n",
    "\n",
    "\n",
    "- Writier : 송영석\n",
    "- Date : 2021.10.10\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-mechanism",
   "metadata": {},
   "source": [
    "- 목적 \n",
    "의미있는 내용의 가사를 작성 할 수 있어야 하므로 적당한 길이의 가사와 의미없거나 짧은 sentence들은 전처리 과정에서 제거해준다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fresh-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-quilt",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리를 위한 분석\n",
    " ### * 문장의 길이를 파악해 추가적으로 전처리\n",
    " ### * [,{,( 등의 기호가 들어간 문장 과감히 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "armed-candy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      " There must be some kind of way outta here\n",
      "Said the joker to the thief\n",
      "There's too much confusion\n",
      "I can't get no relief Business men, they drink my wine\n",
      "Plowman dig my earth\n",
      "None were level on the mind\n",
      "Nobody up at his word\n",
      "Hey, hey No reason to get excited\n",
      "The thief he kindly spoke\n",
      "There are many here among us\n",
      "Who feel that life is but a joke\n",
      "But, uh, but you and I, we've been through that\n",
      "And this is not our fate\n",
      "So let us stop talkin' falsely now\n",
      "The hour's getting late, hey All along the watchtower\n",
      "Princes kept the view\n",
      "While all the women came and went\n",
      "Barefoot servants, too\n",
      "Outside in the cold distance\n",
      "A wildcat did growl\n",
      "Two riders were approaching\n",
      "And the wind began to howl [Intro]\n",
      "Hey Joe\n",
      "Where you going with that gun in your hand?\n",
      "Hey Joe\n",
      "I said where you going with that gun in your hand? [Verse 1]\n",
      "I'm going down to shoot my old lady\n",
      "You know, I caught her messing around with another man\n",
      "I'm going down to shoot my old lady\n",
      "You know, I caught her messing around with another man\n"
     ]
    }
   ],
   "source": [
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "for i in raw_corpus[:30]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-somerset",
   "metadata": {},
   "source": [
    " ### * DataFrame 이용하여 문장 길이별 분포 확인   \n",
    "  - 15 길이까지는 아직 의미 있는 문장으로 보이고 10 부터는 의미가 없어보여서 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "determined-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There must be some kind of way outta here</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Said the joker to the thief</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There's too much confusion</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't get no relief Business men, they drink...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plowman dig my earth</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  length\n",
       "0          There must be some kind of way outta here      42\n",
       "1                        Said the joker to the thief      27\n",
       "2                         There's too much confusion      26\n",
       "3  I can't get no relief Business men, they drink...      54\n",
       "4                               Plowman dig my earth      20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lyr = pd.DataFrame(data = raw_corpus,columns = ['lyrics'])\n",
    "lyr[\"length\"] = lyr[\"lyrics\"].apply(lambda i:len(i))    \n",
    "lyr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floating-little",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Alright</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Hey Joe, uh</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Help me</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ooo, ahhh</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Ooo, ahhh</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Help me</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Oh, no, oh</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Oh, help me</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Purple haze</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Ow foxy lady</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Yeah, foxy</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Oh lady</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Foxy lady</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>It's alright</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>(Yeah)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Now dig this!</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Ha!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>And go on down</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Freedom, yeah</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>If you need me</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lyrics  length\n",
       "22          Hey Joe       7\n",
       "24          Hey Joe       7\n",
       "31          Hey Joe       7\n",
       "34          Hey Joe       7\n",
       "54          Alright       7\n",
       "62          Hey Joe       7\n",
       "65      Hey Joe, uh      11\n",
       "73          Help me       7\n",
       "75        Ooo, ahhh       9\n",
       "76        Ooo, ahhh       9\n",
       "81          Help me       7\n",
       "83       Oh, no, oh      10\n",
       "84      Oh, help me      11\n",
       "87      Purple haze      11\n",
       "92             Foxy       4\n",
       "98             Foxy       4\n",
       "100            Foxy       4\n",
       "109    Ow foxy lady      12\n",
       "111      Yeah, foxy      10\n",
       "113            Foxy       4\n",
       "117         Oh lady       7\n",
       "118            Foxy       4\n",
       "119       Foxy lady       9\n",
       "158    It's alright      12\n",
       "164          (Yeah)       6\n",
       "219   Now dig this!      13\n",
       "220             Ha!       3\n",
       "238  And go on down      14\n",
       "263   Freedom, yeah      13\n",
       "267  If you need me      14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lyr_copy = lyr.copy()\n",
    "\n",
    "lyr_copy = lyr_copy[lyr_copy.length <100] \n",
    "sns.distplot(lyr_copy['length'] , label = \"Lyrics_length\")\n",
    "\n",
    "lyr_copy = lyr_copy[lyr_copy.length <15]\n",
    "lyr_copy.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recreational-planet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Alright</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Hey Joe</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Help me</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ooo, ahhh</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Ooo, ahhh</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Help me</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Oh lady</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Foxy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Foxy lady</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>(Yeah)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Ha!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>We as men</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>(Yeah)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>Hey</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>(Yeah)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Hey!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>Hey yeah!</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Yeah</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Huh huh</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Yeah ow!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Yeah,</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Yeah,</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lyrics  length\n",
       "22     Hey Joe       7\n",
       "24     Hey Joe       7\n",
       "31     Hey Joe       7\n",
       "34     Hey Joe       7\n",
       "54     Alright       7\n",
       "62     Hey Joe       7\n",
       "73     Help me       7\n",
       "75   Ooo, ahhh       9\n",
       "76   Ooo, ahhh       9\n",
       "81     Help me       7\n",
       "92        Foxy       4\n",
       "98        Foxy       4\n",
       "100       Foxy       4\n",
       "113       Foxy       4\n",
       "117    Oh lady       7\n",
       "118       Foxy       4\n",
       "119  Foxy lady       9\n",
       "164     (Yeah)       6\n",
       "220        Ha!       3\n",
       "302  We as men       9\n",
       "405     (Yeah)       6\n",
       "458        Hey       3\n",
       "479     (Yeah)       6\n",
       "527       Hey!       4\n",
       "540  Hey yeah!       9\n",
       "561       Yeah       4\n",
       "624    Huh huh       7\n",
       "694   Yeah ow!       8\n",
       "750      Yeah,       5\n",
       "751      Yeah,       5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyr_copy = lyr_copy[lyr_copy.length <10]\n",
    "lyr_copy.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-answer",
   "metadata": {},
   "source": [
    "## 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "textile-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-condition",
   "metadata": {},
   "source": [
    "### 문장의 길이, ({[- 등의 기호를 포함한 문장을 삭제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handed-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "156078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<start> there must be some kind of way outta here <end>',\n",
       " '<start> said the joker to the thief <end>',\n",
       " '<start> there s too much confusion <end>',\n",
       " '<start> i can t get no relief business men , they drink my wine <end>',\n",
       " '<start> plowman dig my earth <end>',\n",
       " '<start> none were level on the mind <end>',\n",
       " '<start> nobody up at his word <end>',\n",
       " '<start> hey , hey no reason to get excited <end>',\n",
       " '<start> the thief he kindly spoke <end>',\n",
       " '<start> there are many here among us <end>',\n",
       " '<start> who feel that life is but a joke <end>',\n",
       " '<start> but , uh , but you and i , we ve been through that <end>',\n",
       " '<start> and this is not our fate <end>',\n",
       " '<start> so let us stop talkin falsely now <end>',\n",
       " '<start> the hour s getting late , hey all along the watchtower <end>',\n",
       " '<start> princes kept the view <end>',\n",
       " '<start> while all the women came and went <end>',\n",
       " '<start> barefoot servants , too <end>',\n",
       " '<start> outside in the cold distance <end>',\n",
       " '<start> a wildcat did growl <end>',\n",
       " '<start> two riders were approaching <end>',\n",
       " '<start> where you going with that gun in your hand ? <end>',\n",
       " '<start> i m going down to shoot my old lady <end>',\n",
       " '<start> you know , i caught her messing around with another man <end>',\n",
       " '<start> i m going down to shoot my old lady <end>',\n",
       " '<start> you know , i caught her messing around with another man <end>',\n",
       " '<start> i heard you shot your woman down <end>',\n",
       " '<start> shot her down , now <end>',\n",
       " '<start> i heard you shot your old lady down <end>',\n",
       " '<start> yes i did , i shot her <end>',\n",
       " '<start> you know , i caught her messing around , messing around town <end>',\n",
       " '<start> yes i did , i shot her <end>',\n",
       " '<start> you know , i caught my old lady messing around town <end>',\n",
       " '<start> and i gave her the gun <end>',\n",
       " '<start> hey joe , alright <end>',\n",
       " '<start> hey joe , said now <end>',\n",
       " '<start> where you going to run to now ? <end>',\n",
       " '<start> where you going to run to ? <end>',\n",
       " '<start> hey joe , i said <end>',\n",
       " '<start> where you going to run to now ? <end>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "if raw_corpus[21].find(']') != -1:\n",
    "    print(\"exist\")\n",
    "else:\n",
    "    print(\"no\")\n",
    "      \n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    \n",
    "    if len(sentence) < 10: continue\n",
    "    if sentence.find('{') != -1:continue\n",
    "    if sentence.find('[') != -1:continue  \n",
    "    if sentence.find('(') != -1:continue   \n",
    "    if sentence.find('-') != -1:continue\n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "print(len(corpus))\n",
    "corpus[:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "technological-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  63 278 ...   0   0   0]\n",
      " [  2 110   6 ...   0   0   0]\n",
      " [  2  63  17 ...   0   0   0]\n",
      " ...\n",
      " [  2  73  43 ...   3   0   0]\n",
      " [  2  58   4 ...   0   0   0]\n",
      " [  2  13 656 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f47b3b54a50>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(156078, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 12000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
    "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
    "    # 12000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    \n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=15)  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-shade",
   "metadata": {},
   "source": [
    "## 3. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brave-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  63 278  28  95 523  19  84 767  94   3   0   0   0]\n",
      "[ 63 278  28  95 523  19  84 767  94   3   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "musical-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124862, 14)\n",
      "Target Train: (124862, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=20)\n",
    "print(\"Source Train:\", enc_train.shape)  # (124960, 14)  # 현재 (124981, 14)\n",
    "print(\"Target Train:\", dec_train.shape)  # (124960, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ordered-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-slovakia",
   "metadata": {},
   "source": [
    "## 4.인공지능 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sunrise-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-anime",
   "metadata": {},
   "source": [
    "### model_1  \n",
    "embedding_size = 256  \n",
    "hidden_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "progressive-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model_1 = TextGenerator(VOCAB_SIZE, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "still-communist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 8.46847797e-06, -6.49428112e-05,  5.24152674e-05, ...,\n",
       "          6.47936758e-05,  2.10348313e-04, -7.88815742e-05],\n",
       "        [-1.49728687e-04, -9.94259171e-05,  8.68671341e-05, ...,\n",
       "          5.59657856e-05,  2.99001025e-04, -3.86196218e-04],\n",
       "        [-1.33137306e-04, -3.02586268e-04,  4.21381555e-05, ...,\n",
       "          7.22256591e-05,  3.85704072e-04, -2.94935919e-04],\n",
       "        ...,\n",
       "        [-9.43291641e-04,  9.61448881e-04, -1.11650047e-03, ...,\n",
       "          1.63183932e-03, -2.96230937e-05, -3.25290457e-04],\n",
       "        [-1.15747645e-03,  1.43469265e-03, -1.12258678e-03, ...,\n",
       "          1.77344552e-03, -7.92839855e-05, -5.18048590e-04],\n",
       "        [-1.35931745e-03,  1.85808679e-03, -1.14271848e-03, ...,\n",
       "          1.89660222e-03, -1.39492215e-04, -7.24249228e-04]],\n",
       "\n",
       "       [[ 8.46847797e-06, -6.49428112e-05,  5.24152674e-05, ...,\n",
       "          6.47936758e-05,  2.10348313e-04, -7.88815742e-05],\n",
       "        [ 1.97327492e-04, -3.29684641e-04,  1.59463394e-04, ...,\n",
       "         -4.97284200e-05,  2.94030178e-04, -2.60108427e-05],\n",
       "        [ 4.64949553e-05, -3.31836374e-04,  6.09148010e-05, ...,\n",
       "         -2.83002184e-04,  2.32619423e-04, -1.43170982e-04],\n",
       "        ...,\n",
       "        [-9.82033234e-05,  2.56818184e-03, -8.23402544e-04, ...,\n",
       "          5.79554297e-04,  2.89002899e-04, -5.68546704e-04],\n",
       "        [-3.68771638e-04,  2.85915355e-03, -9.33384057e-04, ...,\n",
       "          8.32868565e-04,  2.11683422e-04, -7.61045201e-04],\n",
       "        [-6.31533156e-04,  3.09429411e-03, -1.04208314e-03, ...,\n",
       "          1.06640288e-03,  1.23453094e-04, -9.59309866e-04]],\n",
       "\n",
       "       [[ 8.46847797e-06, -6.49428112e-05,  5.24152674e-05, ...,\n",
       "          6.47936758e-05,  2.10348313e-04, -7.88815742e-05],\n",
       "        [-5.61065608e-05, -4.52947861e-04,  2.31678161e-04, ...,\n",
       "          2.35416504e-04,  4.32003144e-04, -4.27215673e-05],\n",
       "        [ 2.84811704e-05, -7.99624948e-04,  4.05800674e-04, ...,\n",
       "          2.78622785e-04,  6.22436346e-04,  9.89494292e-05],\n",
       "        ...,\n",
       "        [ 8.84278270e-05,  1.83513825e-04,  6.69846253e-04, ...,\n",
       "          1.07548910e-03,  3.30436131e-04,  1.67095845e-04],\n",
       "        [ 5.14726911e-04,  3.40958941e-04,  5.48913435e-04, ...,\n",
       "          7.18013558e-04,  3.72818351e-04,  6.20500396e-06],\n",
       "        [ 6.08171918e-04,  7.22237455e-04,  3.68866109e-04, ...,\n",
       "          5.79286134e-04,  3.61205690e-04, -1.72768123e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.46847797e-06, -6.49428112e-05,  5.24152674e-05, ...,\n",
       "          6.47936758e-05,  2.10348313e-04, -7.88815742e-05],\n",
       "        [ 1.11357505e-04, -8.66509436e-05,  1.52543798e-04, ...,\n",
       "         -1.39147203e-04,  3.03531706e-04,  3.95905554e-05],\n",
       "        [ 1.46625971e-04, -1.40388991e-04,  3.46408342e-04, ...,\n",
       "         -3.87737877e-04, -6.24185559e-05,  1.86419365e-05],\n",
       "        ...,\n",
       "        [-2.65481271e-04, -8.96355661e-04,  5.62073081e-04, ...,\n",
       "          1.84011378e-03, -1.65067788e-03, -4.73830412e-04],\n",
       "        [-2.83884990e-04, -4.31638153e-04,  3.69651709e-04, ...,\n",
       "          1.90551451e-03, -1.48059020e-03, -4.88127378e-04],\n",
       "        [-4.13673028e-04,  1.28318265e-04,  1.85335710e-04, ...,\n",
       "          1.95332477e-03, -1.27065729e-03, -5.55996434e-04]],\n",
       "\n",
       "       [[ 8.46847797e-06, -6.49428112e-05,  5.24152674e-05, ...,\n",
       "          6.47936758e-05,  2.10348313e-04, -7.88815742e-05],\n",
       "        [ 1.27713065e-04, -3.54051444e-04,  1.05429513e-04, ...,\n",
       "          2.28352073e-04,  2.94235913e-04, -7.23802150e-05],\n",
       "        [ 6.60986188e-07, -5.21262817e-04,  1.15527451e-04, ...,\n",
       "          2.04021155e-04,  3.21794185e-04, -3.70436203e-04],\n",
       "        ...,\n",
       "        [-6.14599150e-04,  1.79534080e-03, -3.13009077e-04, ...,\n",
       "          2.82628316e-04,  7.17760850e-05, -7.76953762e-04],\n",
       "        [-8.19029636e-04,  2.14759191e-03, -4.75791865e-04, ...,\n",
       "          5.51789708e-04,  1.33401772e-05, -9.66267835e-04],\n",
       "        [-1.01789378e-03,  2.45004450e-03, -6.22108346e-04, ...,\n",
       "          8.05100368e-04, -5.58086867e-05, -1.16011337e-03]],\n",
       "\n",
       "       [[-2.55671621e-04, -5.15526881e-05,  9.64181891e-05, ...,\n",
       "          3.76818934e-06,  1.33667912e-04, -4.97097381e-06],\n",
       "        [-5.85577101e-04,  3.03236866e-05,  5.04259253e-04, ...,\n",
       "          8.70645017e-05,  2.79693573e-04,  4.27886174e-04],\n",
       "        [-7.09705288e-04,  1.49586805e-04,  6.09530020e-04, ...,\n",
       "          8.63940586e-05,  4.08373715e-04,  8.24824558e-04],\n",
       "        ...,\n",
       "        [-1.96251110e-03,  1.84566597e-04, -1.10429840e-03, ...,\n",
       "         -1.00366795e-03, -8.31740559e-04,  2.94306054e-04],\n",
       "        [-1.77501654e-03,  4.13839618e-04, -1.02624088e-03, ...,\n",
       "         -1.01456454e-03, -9.12447518e-04,  2.37022788e-04],\n",
       "        [-1.46568136e-03,  4.49941901e-04, -1.01005589e-03, ...,\n",
       "         -7.85093696e-04, -6.73143135e-04,  2.45133924e-05]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model_1(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "given-vacuum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excellent-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3902/3902 [==============================] - 335s 85ms/step - loss: 3.6299 - val_loss: 3.0368\n",
      "Epoch 2/10\n",
      "3902/3902 [==============================] - 333s 85ms/step - loss: 2.8998 - val_loss: 2.8302\n",
      "Epoch 3/10\n",
      "3902/3902 [==============================] - 331s 85ms/step - loss: 2.5853 - val_loss: 2.7107\n",
      "Epoch 4/10\n",
      "3902/3902 [==============================] - 331s 85ms/step - loss: 2.3038 - val_loss: 2.6381\n",
      "Epoch 5/10\n",
      "3902/3902 [==============================] - 333s 85ms/step - loss: 2.0618 - val_loss: 2.5984\n",
      "Epoch 6/10\n",
      "3902/3902 [==============================] - 332s 85ms/step - loss: 1.8379 - val_loss: 2.5811\n",
      "Epoch 7/10\n",
      "3902/3902 [==============================] - 331s 85ms/step - loss: 1.6578 - val_loss: 2.5830\n",
      "Epoch 8/10\n",
      "3902/3902 [==============================] - 333s 85ms/step - loss: 1.4993 - val_loss: 2.5901\n",
      "Epoch 9/10\n",
      "3902/3902 [==============================] - 331s 85ms/step - loss: 1.3661 - val_loss: 2.6194\n",
      "Epoch 10/10\n",
      "3902/3902 [==============================] - 331s 85ms/step - loss: 1.2532 - val_loss: 2.6589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f479583bad0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model_1.compile(loss=loss, optimizer=optimizer)\n",
    "model_1.fit(enc_train, dec_train, validation_data=(enc_val, dec_val),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-alloy",
   "metadata": {},
   "source": [
    "### model_2  \n",
    "embedding_size = 512   \n",
    "hidden_size = 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "super-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "embedding_size = 512\n",
    "hidden_size = 2048\n",
    "model_2 = TextGenerator(VOCAB_SIZE, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rocky-trailer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 4.35541515e-05,  3.78803408e-04,  2.32230857e-04, ...,\n",
       "          1.92466483e-04, -2.81414250e-04, -1.58785959e-04],\n",
       "        [ 2.54317041e-04,  4.37848648e-04,  3.81432852e-04, ...,\n",
       "          4.83196840e-04, -4.22750672e-05, -1.81578638e-04],\n",
       "        [ 1.92054664e-04,  3.96739488e-04,  8.46584560e-04, ...,\n",
       "          5.30437334e-04,  1.65375561e-04, -1.88945720e-04],\n",
       "        ...,\n",
       "        [ 3.37911828e-04, -3.50256218e-03, -7.99990841e-04, ...,\n",
       "         -2.77873303e-04,  2.52581784e-03, -2.68235453e-03],\n",
       "        [ 4.21669974e-04, -4.15304489e-03, -7.18562398e-04, ...,\n",
       "         -4.25423612e-04,  3.08939791e-03, -3.43639869e-03],\n",
       "        [ 4.84564254e-04, -4.70366376e-03, -5.97764913e-04, ...,\n",
       "         -5.32154692e-04,  3.58104077e-03, -4.14630724e-03]],\n",
       "\n",
       "       [[ 4.35541515e-05,  3.78803408e-04,  2.32230857e-04, ...,\n",
       "          1.92466483e-04, -2.81414250e-04, -1.58785959e-04],\n",
       "        [ 3.36625235e-04,  6.18739170e-04,  7.05229759e-04, ...,\n",
       "          2.41691741e-04, -3.31756368e-04, -5.94689045e-05],\n",
       "        [ 1.79383977e-04,  5.85596135e-04,  7.72959960e-04, ...,\n",
       "          4.04645951e-04, -2.82400346e-04, -2.22094546e-04],\n",
       "        ...,\n",
       "        [ 1.99424918e-03, -5.35349362e-04, -5.04546566e-04, ...,\n",
       "          5.12040278e-04,  8.77800223e-04, -9.58877645e-05],\n",
       "        [ 2.24163919e-03, -1.39938667e-03, -4.37425508e-04, ...,\n",
       "          1.96506138e-04,  1.37929711e-03, -6.12063915e-04],\n",
       "        [ 2.39827251e-03, -2.31137709e-03, -3.62106570e-04, ...,\n",
       "         -1.16009905e-04,  1.94330944e-03, -1.24828017e-03]],\n",
       "\n",
       "       [[-1.01255209e-04, -1.68181970e-04,  1.31361070e-04, ...,\n",
       "         -2.79678992e-04, -5.21845914e-06,  9.29333619e-05],\n",
       "        [ 3.11072916e-04, -2.95976351e-04,  5.18978923e-05, ...,\n",
       "         -1.56082358e-04,  8.75318583e-05,  4.78649192e-04],\n",
       "        [ 3.33619071e-04, -3.88688612e-04,  4.09167784e-04, ...,\n",
       "         -1.95993009e-04,  4.55990725e-04,  7.18046445e-04],\n",
       "        ...,\n",
       "        [-3.62522318e-04, -4.39380819e-04, -8.71682889e-04, ...,\n",
       "         -2.83987029e-03, -1.05142986e-04,  3.85467341e-04],\n",
       "        [-3.57600686e-04, -5.73134690e-04, -1.36648724e-03, ...,\n",
       "         -2.63784290e-03, -1.57965987e-04,  4.40355041e-04],\n",
       "        [-4.53557295e-04, -9.25792265e-04, -1.52003823e-03, ...,\n",
       "         -2.34931824e-03,  1.08974295e-04,  2.67227617e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.35541515e-05,  3.78803408e-04,  2.32230857e-04, ...,\n",
       "          1.92466483e-04, -2.81414250e-04, -1.58785959e-04],\n",
       "        [ 1.02557846e-04,  3.09500087e-04,  2.53995007e-04, ...,\n",
       "          5.18133980e-04, -6.09430019e-04, -7.00218807e-05],\n",
       "        [-9.63664497e-05,  5.21624403e-04,  3.15560203e-04, ...,\n",
       "          8.21318652e-04, -8.74281453e-04, -4.17112518e-04],\n",
       "        ...,\n",
       "        [-8.74244433e-04, -3.14936880e-03, -1.57409086e-04, ...,\n",
       "         -2.73182988e-04,  1.77736534e-03, -3.94798443e-03],\n",
       "        [-5.86541020e-04, -3.74275376e-03, -1.02029924e-04, ...,\n",
       "         -4.18714422e-04,  2.44944100e-03, -4.39103507e-03],\n",
       "        [-3.40174738e-04, -4.25221492e-03, -1.93839587e-05, ...,\n",
       "         -5.20205591e-04,  3.03156115e-03, -4.83299466e-03]],\n",
       "\n",
       "       [[ 4.35541515e-05,  3.78803408e-04,  2.32230857e-04, ...,\n",
       "          1.92466483e-04, -2.81414250e-04, -1.58785959e-04],\n",
       "        [-1.47095576e-04,  6.16711099e-04,  3.62695078e-04, ...,\n",
       "          5.65253315e-04, -5.24773495e-04, -2.78041494e-04],\n",
       "        [-3.55664844e-04,  4.67752310e-04,  8.77228624e-04, ...,\n",
       "          6.59201469e-04, -6.49348891e-04, -9.63234925e-05],\n",
       "        ...,\n",
       "        [ 4.70506580e-04, -3.94635275e-03,  5.33528451e-04, ...,\n",
       "         -5.95880556e-04,  2.51390645e-03, -2.93944078e-03],\n",
       "        [ 4.93007596e-04, -4.51973965e-03,  5.12838305e-04, ...,\n",
       "         -6.57920493e-04,  3.08081880e-03, -3.68804531e-03],\n",
       "        [ 4.99779591e-04, -5.00200829e-03,  5.30173362e-04, ...,\n",
       "         -6.78985671e-04,  3.56335682e-03, -4.37338790e-03]],\n",
       "\n",
       "       [[ 4.35541515e-05,  3.78803408e-04,  2.32230857e-04, ...,\n",
       "          1.92466483e-04, -2.81414250e-04, -1.58785959e-04],\n",
       "        [ 3.36625235e-04,  6.18739170e-04,  7.05229759e-04, ...,\n",
       "          2.41691741e-04, -3.31756368e-04, -5.94689045e-05],\n",
       "        [ 1.17263044e-04,  7.98341294e-04,  9.68876295e-04, ...,\n",
       "          1.08606480e-04,  7.23325093e-06,  1.52020584e-04],\n",
       "        ...,\n",
       "        [ 4.30950633e-04, -5.03492833e-04,  6.80047960e-04, ...,\n",
       "          6.92622154e-04,  1.02283934e-03, -1.07690552e-03],\n",
       "        [ 6.72086899e-04, -1.26519660e-03,  3.49000300e-04, ...,\n",
       "          5.61828550e-04,  1.63978734e-03, -1.58581114e-03],\n",
       "        [ 8.82957655e-04, -2.08952324e-03,  7.88248217e-05, ...,\n",
       "          3.69183050e-04,  2.29812926e-03, -2.17703474e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model_2(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "identical-converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  18882560  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 80,107,489\n",
      "Trainable params: 80,107,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "professional-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3902/3902 [==============================] - 928s 237ms/step - loss: 3.4687 - val_loss: 2.8177\n",
      "Epoch 2/10\n",
      "3902/3902 [==============================] - 926s 237ms/step - loss: 2.5602 - val_loss: 2.5433\n",
      "Epoch 3/10\n",
      "3902/3902 [==============================] - 926s 237ms/step - loss: 2.0193 - val_loss: 2.4033\n",
      "Epoch 4/10\n",
      "3902/3902 [==============================] - 928s 238ms/step - loss: 1.5968 - val_loss: 2.3616\n",
      "Epoch 5/10\n",
      "3902/3902 [==============================] - 923s 237ms/step - loss: 1.3139 - val_loss: 2.3787\n",
      "Epoch 6/10\n",
      "3902/3902 [==============================] - 925s 237ms/step - loss: 1.1477 - val_loss: 2.4379\n",
      "Epoch 7/10\n",
      "3902/3902 [==============================] - 924s 237ms/step - loss: 1.0586 - val_loss: 2.4907\n",
      "Epoch 8/10\n",
      "3902/3902 [==============================] - 929s 238ms/step - loss: 1.0139 - val_loss: 2.5445\n",
      "Epoch 9/10\n",
      "3902/3902 [==============================] - 921s 236ms/step - loss: 0.9885 - val_loss: 2.5903\n",
      "Epoch 10/10\n",
      "3902/3902 [==============================] - 924s 237ms/step - loss: 0.9752 - val_loss: 2.6241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4796b0fd10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model_2.compile(loss=loss, optimizer=optimizer)\n",
    "model_2.fit(enc_train, dec_train, validation_data=(enc_val, dec_val),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-selling",
   "metadata": {},
   "source": [
    "### model_3 \n",
    "embedding_size = 1024   \n",
    "hidden_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efficient-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 1024\n",
    "hidden_size = 2048\n",
    "model_3 = TextGenerator(VOCAB_SIZE, embedding_size , hidden_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "visible-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "embedding_size = 512\n",
    "hidden_size = 2048\n",
    "model_3 = TextGenerator(VOCAB_SIZE, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "decreased-evening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-1.21695208e-04,  8.90151641e-05, -6.68824214e-05, ...,\n",
       "         -5.94193189e-05, -9.40204627e-05,  4.72090105e-05],\n",
       "        [-1.00934434e-04, -9.26813736e-05, -1.27088961e-05, ...,\n",
       "          6.42399682e-05, -1.59082396e-04,  9.75036091e-05],\n",
       "        [ 4.76345507e-04, -1.68108134e-04,  4.90210776e-04, ...,\n",
       "          2.40156514e-05,  1.11267029e-04, -2.95695412e-04],\n",
       "        ...,\n",
       "        [-4.52685577e-04, -1.51059439e-03,  1.93130958e-03, ...,\n",
       "         -1.00087316e-03,  1.75794354e-03, -1.47509086e-03],\n",
       "        [-1.47464962e-04, -1.33017637e-03,  1.75278250e-03, ...,\n",
       "         -1.57233409e-03,  2.10758019e-03, -2.25873035e-03],\n",
       "        [ 1.45905899e-04, -1.16435427e-03,  1.58808951e-03, ...,\n",
       "         -2.18766672e-03,  2.37694383e-03, -2.88372836e-03]],\n",
       "\n",
       "       [[-1.21695208e-04,  8.90151641e-05, -6.68824214e-05, ...,\n",
       "         -5.94193189e-05, -9.40204627e-05,  4.72090105e-05],\n",
       "        [-5.86702547e-04, -5.53637146e-05,  3.36851634e-04, ...,\n",
       "         -3.47655499e-04, -4.73918743e-04,  2.36053180e-04],\n",
       "        [-7.55226647e-04, -1.34234389e-04,  8.63039400e-04, ...,\n",
       "         -2.27664190e-04, -3.23417946e-04,  1.84686389e-04],\n",
       "        ...,\n",
       "        [-6.46529486e-04,  8.14267958e-04,  1.21754699e-03, ...,\n",
       "         -2.13807984e-03, -5.54879603e-04, -1.19737687e-03],\n",
       "        [-4.50767577e-04,  7.53897068e-04,  1.15656620e-03, ...,\n",
       "         -2.49879411e-03, -1.77362424e-04, -1.88883848e-03],\n",
       "        [-1.69203035e-04,  7.49666651e-04,  1.05911796e-03, ...,\n",
       "         -2.86345370e-03,  2.27802084e-04, -2.63338746e-03]],\n",
       "\n",
       "       [[-1.21695208e-04,  8.90151641e-05, -6.68824214e-05, ...,\n",
       "         -5.94193189e-05, -9.40204627e-05,  4.72090105e-05],\n",
       "        [-1.81017065e-04,  4.93050553e-04,  4.79989016e-04, ...,\n",
       "         -2.00234441e-04, -2.62514106e-04,  1.36554721e-04],\n",
       "        [-2.39356683e-04,  1.19682627e-04,  9.71376954e-04, ...,\n",
       "         -3.02931148e-04, -2.99482781e-04, -7.04587292e-05],\n",
       "        ...,\n",
       "        [ 5.73194120e-04, -4.96820314e-04,  1.05717417e-03, ...,\n",
       "         -2.62457645e-03,  7.79928348e-04, -3.38673336e-03],\n",
       "        [ 7.11400819e-04, -3.55716620e-04,  1.04743987e-03, ...,\n",
       "         -3.14696506e-03,  1.09804829e-03, -3.96049581e-03],\n",
       "        [ 8.14024417e-04, -2.72624748e-04,  1.04917819e-03, ...,\n",
       "         -3.64802266e-03,  1.35626341e-03, -4.36064182e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.68957631e-04,  1.52983339e-04,  5.17657136e-05, ...,\n",
       "          1.62407639e-04,  2.54338374e-04,  1.10671726e-05],\n",
       "        [-2.70248827e-04,  5.02793991e-04,  1.58394294e-04, ...,\n",
       "          2.28013640e-04,  2.81611428e-04,  5.54917569e-05],\n",
       "        [-2.51836154e-05,  5.95181424e-04,  3.01407039e-04, ...,\n",
       "          1.94962049e-04,  2.71548808e-04,  1.53556422e-04],\n",
       "        ...,\n",
       "        [-5.90998679e-04, -1.15735270e-03,  5.93734032e-04, ...,\n",
       "          7.09149870e-04, -8.57732142e-04,  2.61072564e-04],\n",
       "        [-7.48786435e-04, -7.03970436e-04,  3.99004552e-04, ...,\n",
       "          1.04924419e-03, -1.10149477e-03,  8.26711475e-04],\n",
       "        [-5.15606895e-04, -1.02642016e-03,  4.72346204e-04, ...,\n",
       "          1.45220675e-03, -1.31980167e-03,  9.69919434e-04]],\n",
       "\n",
       "       [[-1.21695208e-04,  8.90151641e-05, -6.68824214e-05, ...,\n",
       "         -5.94193189e-05, -9.40204627e-05,  4.72090105e-05],\n",
       "        [-6.44773900e-06, -8.45093600e-05, -1.50437045e-04, ...,\n",
       "          9.58240344e-05, -4.17173374e-04, -1.51880027e-04],\n",
       "        [-4.10131506e-05, -4.11336396e-06,  5.25654505e-05, ...,\n",
       "         -2.94515048e-05, -6.65376021e-04, -5.84648398e-04],\n",
       "        ...,\n",
       "        [ 1.39678712e-03, -9.72213340e-04,  7.02167687e-04, ...,\n",
       "         -3.78907286e-03,  1.90134556e-03, -4.44471603e-03],\n",
       "        [ 1.41999975e-03, -9.75128671e-04,  7.61549571e-04, ...,\n",
       "         -4.34280746e-03,  2.04162230e-03, -4.57486790e-03],\n",
       "        [ 1.41547713e-03, -9.97621217e-04,  8.37412197e-04, ...,\n",
       "         -4.83945943e-03,  2.13952130e-03, -4.62870346e-03]],\n",
       "\n",
       "       [[-1.21695208e-04,  8.90151641e-05, -6.68824214e-05, ...,\n",
       "         -5.94193189e-05, -9.40204627e-05,  4.72090105e-05],\n",
       "        [-2.63376161e-04, -2.04269032e-04, -8.20727146e-05, ...,\n",
       "         -1.12433823e-04, -2.34850784e-04, -1.83176599e-04],\n",
       "        [-7.03772646e-04, -9.84825965e-05, -5.11415710e-05, ...,\n",
       "         -5.48137759e-05, -5.60012937e-04, -1.74224391e-04],\n",
       "        ...,\n",
       "        [-7.49602681e-04, -3.88065004e-04,  7.28860672e-04, ...,\n",
       "         -1.29327830e-03, -5.88248076e-04,  1.05935836e-03],\n",
       "        [-3.70495138e-04, -3.10566858e-04,  8.47233750e-04, ...,\n",
       "         -1.86493446e-03, -3.20663967e-05,  1.71703316e-04],\n",
       "        [-1.45309596e-05, -2.89946736e-04,  9.39314545e-04, ...,\n",
       "         -2.48470088e-03,  4.49573359e-04, -7.19467353e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model_3(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ancient-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      multiple                  6144512   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               multiple                  20979712  \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 85,276,897\n",
      "Trainable params: 85,276,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "accessible-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3902/3902 [==============================] - 924s 236ms/step - loss: 3.4639 - val_loss: 2.8500\n",
      "Epoch 2/10\n",
      "3902/3902 [==============================] - 918s 235ms/step - loss: 2.6113 - val_loss: 2.5751\n",
      "Epoch 3/10\n",
      "3902/3902 [==============================] - 921s 236ms/step - loss: 2.0814 - val_loss: 2.4249\n",
      "Epoch 4/10\n",
      "3902/3902 [==============================] - 920s 236ms/step - loss: 1.6526 - val_loss: 2.3666\n",
      "Epoch 5/10\n",
      "3902/3902 [==============================] - 919s 236ms/step - loss: 1.3529 - val_loss: 2.3781\n",
      "Epoch 6/10\n",
      "3902/3902 [==============================] - 917s 235ms/step - loss: 1.1701 - val_loss: 2.4293\n",
      "Epoch 7/10\n",
      "3902/3902 [==============================] - 918s 235ms/step - loss: 1.0698 - val_loss: 2.4882\n",
      "Epoch 8/10\n",
      "3902/3902 [==============================] - 918s 235ms/step - loss: 1.0169 - val_loss: 2.5484\n",
      "Epoch 9/10\n",
      "3902/3902 [==============================] - 919s 235ms/step - loss: 0.9859 - val_loss: 2.5843\n",
      "Epoch 10/10\n",
      "3902/3902 [==============================] - 917s 235ms/step - loss: 0.9687 - val_loss: 2.6232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f46e82fd690>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model_3.compile(loss=loss, optimizer=optimizer)\n",
    "model_3.fit(enc_train, dec_train, validation_data=(enc_val, dec_val),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "lined-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "piano-small",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , liberian girl , <end> '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_3, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "organizational-rochester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> every time i fuck him i say whose is it ? <end> '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_3, tokenizer, init_sentence=\"<start> every\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "spectacular-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> money talks nixga im caught up in that gossip <end> '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_3, tokenizer, init_sentence=\"<start> money\" , max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-october",
   "metadata": {},
   "source": [
    "# 회고\n",
    " - 데이터를 정제해야함으로 가사 파일들을 하나씩 열어보면서 '[Verse]'나 '(영어)' or {'영어'} 형식으로 되있는 것들을 발견하였고 이들은 가사 형성에 도움이 되지 않으므로 과감히 문장을 제거하였습니다.\n",
    " - 정제과정에서 길이가 0인 문장뿐아니라 길이가 10미만인 것들은 어떠한 의미를 가진 문장을 형성하기 어렵다고 판단하여 삭제하였습니다.\n",
    " - 위처럼 만들어진 corpus로 토큰화하고 Data를 분리하였습니다.\n",
    " -  모델의 생성과 학습과정에서는 validation loss 를 2.2 이하로 줄이기 위한 노력을 하였습니다. 다른 값들은 고정하고 embedding_size와 hidden_size를 조정하여 validation loss를 적정값으로 만들었습니다. \n",
    "   - model_1은 embedding_size = 256, hidden_size = 1024, val_loss = 2.65\n",
    "   - model_2는 embedding_size = 512, hidden_size = 2048, val_loss = 2.62\n",
    "   - model_3는 embedding_size = 1024, hidden_size = 2048 val_loss = 2.62\n",
    " - 파라미터 설정에 따라 val_loss가 어떻게 얼마나 달라지는지 확인할 수 있었습니다.\n",
    " - 주어진것 이외에도 문장이 잘 생성되는것을 확인하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-stewart",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
